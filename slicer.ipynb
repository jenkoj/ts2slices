{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMESERIES TO IMAGE CONVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk import DataSet\n",
    "import numpy as np\n",
    "\n",
    "from utils.log import print_parameters, print_progress, print_log, print_end, print_end_of_loop\n",
    "from utils.init import get_appliances, param_setup\n",
    "from utils.file_handling import store_many_hdf5, create_file\n",
    "from utils.data_handling import mount_data, append_images\n",
    "from utils.filters import filter_empty_slices_and_fill_missing_samples, filter_low_entropy_slices\n",
    "from utils.process import get_state, moving_window\n",
    "\n",
    "dataset_name = \"iawe\"\n",
    "dataset = DataSet('datasets/'+dataset_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = {\n",
    "    'step_in_mins': 60, # Window size\n",
    "    'max_images': 10000000, # Number of images per appliance per building.\n",
    "    'frames': 1, # Video frames\n",
    "    'allowed_delta_between_frames': 600, # Allowed time difference between frames.\n",
    "    'resample_period': 6, # Resamples time series data to given resample period. Sample period of dataset can be found in dataset.metadata\n",
    "    'fill_limit': 100, # Limit of how many samples to backfill when resampling, larger back fill should yield larger output. \n",
    "    'percentage_of_missing_data_allowed': 0.80, # Missing data will be backfilled.\n",
    "    'sig_save': True, # Save source power signal.\n",
    "    'ts_save': True, # Save source time stamps.\n",
    "    'state_save': True, # Save state of slice (on or off).\n",
    "    'multiple_buildings': True, # If false it processes only one building.\n",
    "    'selected_building': 1, # Used if parameter above is False.\n",
    "    'manually_select_appliances': False # Can be set in get_appliances() function.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixes possible misconfiguration and obtains metadata.\n",
    "param_setup(dataset,par)\n",
    "\n",
    "par[\"appliances\"] = get_appliances(dataset,par)\n",
    "print_parameters(par)\n",
    "file_name = create_file(par)\n",
    "\n",
    "# Define global metrics.\n",
    "healthy_appliances = set()\n",
    "sig_stacked = 0 \n",
    "sig_stacked_per_appliance = 0 \n",
    "\n",
    "# Collect at least \"max_dataset_size\" images for each appliance for every building.\n",
    "for appliance in par[\"appliances\"]:\n",
    "\n",
    "    print_log(par,\"\\n\",\"Starting \"f\"{appliance} (\"f\"{par['appliances'].index(appliance)+1}/\"f\"{len(par['appliances'])}):\")\n",
    "\n",
    "    # Define metric.\n",
    "    sig_stacked_per_appliance = 0\n",
    "    \n",
    "    # Loop through all buildings.\n",
    "    for building in dataset.buildings:\n",
    "        print_log(par,\"\\n\",\"Starting building \"f\"{building}\")\n",
    "\n",
    "        # Define temporary array to store image / frames. \n",
    "        sig_stack_tmp = np.zeros([0, par[\"ts_size\"]])\n",
    "        timestamp_stack_tmp = np.zeros([0, par[\"ts_size\"]])\n",
    "        state_stack_tmp = np.zeros(0)\n",
    "        \n",
    "        # Define main array for video to store.\n",
    "        sig_stack = np.zeros([0, par[\"frames\"], par[\"ts_size\"]])\n",
    "        timestamp_stack = np.zeros([0, par[\"frames\"], par[\"ts_size\"]])\n",
    "        state_stack = np.zeros([0,par[\"frames\"]])\n",
    "\n",
    "        # Use only selected building.\n",
    "        if par[\"multiple_buildings\"] == False:\n",
    "            if int(building)  != par[\"selected_building\"]:\n",
    "                print_log(par,\"skipping building \"f\"{building} due to parameter multiple_buildings \")\n",
    "                continue\n",
    "        \n",
    "        # Filter out labels (appliances) with appliance.\n",
    "        for meter in dataset.buildings[building].elec.submeters().meters:  \n",
    "            \n",
    "            # Get appliance name.\n",
    "            label = meter.appliances[0].metadata.get(\"type\")\n",
    "            \n",
    "            # Continue only for appliance from the main loop.\n",
    "            if label != appliance : continue \n",
    "\n",
    "            # Load data into RAM.\n",
    "            signal,time_stamps = mount_data(meter, par)\n",
    "\n",
    "            # Slice time stamps and signal data to specified length.\n",
    "            time_stamps_slices = moving_window(time_stamps, par[\"ts_size\"])\n",
    "            signal_slices = moving_window(signal, par[\"ts_size\"])\n",
    "\n",
    "            print(\"1\",signal_slices.shape)\n",
    "            # Filter out low entropy data. \n",
    "            signal_slices, time_stamps_slices = filter_empty_slices_and_fill_missing_samples(signal_slices, time_stamps_slices, par)\n",
    "\n",
    "            print(\"2\",signal_slices.shape)\n",
    "            if par[\"state_save\"] == False:\n",
    "                signal_slices, time_stamps_slices = filter_low_entropy_slices(signal_slices, time_stamps_slices, print_parameters)\n",
    "            \n",
    "            print(\"3\",signal_slices.shape)\n",
    "            print_log(par, \"Finished pre-processing! appending...\")\n",
    "\n",
    "            # Continue if no data.\n",
    "            if signal_slices.shape[0] == 0: continue\n",
    "        \n",
    "            # Define metrics.\n",
    "            last_stamp = 0 # Used in append_images for calculating time delta.\n",
    "            next_percent = 10 # Variable helps reduce log output in print_progress().\n",
    "\n",
    "            # Transform pre-processed signal slices. \n",
    "            for i, [sig, time_stamps] in enumerate(zip(signal_slices, time_stamps_slices)):\n",
    "    \n",
    "                next_percent = print_progress(i, signal_slices, sig_stack, next_percent, par)\n",
    "\n",
    "                # Stop if enough data.\n",
    "                if sig_stack.shape[0] >= par[\"max_images\"]:\n",
    "                    print_log(par,\"max size of \"f\"{par['max_images']} reached, skipping!\")\n",
    "                    break\n",
    "\n",
    "                if par[\"state_save\"]:\n",
    "                    sig, state = get_state(sig, par)\n",
    "                else:\n",
    "                    state = 1\n",
    "\n",
    "                # Append transformed images to stack.\n",
    "                state_stack, state_stack_tmp, sig_stack, sig_stack_tmp, timestamp_stack, timestamp_stack_tmp, last_stamp = append_images(state, state_stack, state_stack_tmp,\n",
    "                                                                                               sig, sig_stack, sig_stack_tmp,\n",
    "                                                                                               timestamp_stack, timestamp_stack_tmp,\n",
    "                                                                                               time_stamps, last_stamp, par) \n",
    "        \n",
    "        if sig_stack.shape[0] > 0:\n",
    "            # Save images.\n",
    "            group_path = f\"{par['dataset_name']}/\"f\"{appliance}/\"f\"{building}\"\n",
    "\n",
    "            print(\"signal\",sig_stack.shape)\n",
    "            print(\"ts\", timestamp_stack.shape)\n",
    "            print(\"lab\",state_stack.shape)\n",
    "            \n",
    "            # Update metrics.\n",
    "            sig_stacked_per_appliance += sig_stack.shape[0]\n",
    "            sig_stacked += sig_stack.shape[0]\n",
    "            healthy_appliances.add(appliance)\n",
    "            \n",
    "            if par[\"sig_save\"]:\n",
    "                # Save source time series.\n",
    "                store_many_hdf5(file_name, sig_stack, group_path, \"sig\", force_del=\"yes\")\n",
    "\n",
    "            if par[\"ts_save\"]:\n",
    "                # Save source time series.\n",
    "                store_many_hdf5(file_name, timestamp_stack, group_path, \"ts\", force_del=\"yes\")\n",
    "\n",
    "            if par[\"state_save\"]:\n",
    "                # Save state of slice (on or off).\n",
    "                store_many_hdf5(file_name, state_stack, group_path, \"state\", force_del=\"yes\")\n",
    "        \n",
    "        else:\n",
    "            print_log(par,\"empty for building\", building, \"appliance\", appliance)\n",
    "  \n",
    "        print_log(par, \"finished building N\", building)\n",
    "    \n",
    "    print_end_of_loop(sig_stacked_per_appliance, appliance, par)\n",
    "    \n",
    "print_end(sig_stacked, healthy_appliances, par)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
